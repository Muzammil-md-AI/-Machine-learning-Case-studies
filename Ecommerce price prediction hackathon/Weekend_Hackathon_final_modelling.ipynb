{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E-commerce Price Prediction: Weekend Hackathon #8 (Modelling)\n",
    "\n",
    "--------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "![Alt_text](https://www.machinehack.com/wp-content/uploads/2020/06/E-COMMERCEBANNER-02-1536x864.jpg)\n",
    "\n",
    "E-commerce platforms have been in existence for more than 2 decades now. The popularity and its preference as a common choice for buying and selling essential products have grown rapidly and exponentially over the past few years. E-commerce has impacted the lifestyle of common people to a huge extent. Many such platforms are competing over each other for dominance by providing consumer goods at a competitive price. In this hackathon, we challenge data science enthusiasts to predict the price of commodities on an e-commerce platform.\n",
    "\n",
    "Given are 7 distinguishing factors that can influence the price of a product on an e-commerce platform. Your objective as a data scientist is to build a machine learning model that can accurately predict the price of a product based on the given factors.\n",
    "\n",
    "\n",
    "**Data Description:-**\n",
    "\n",
    "The unzipped folder will have the following files.\n",
    "\n",
    "* Train.csv –  2452 observations.\n",
    "* Test.csv –  1051 observations.\n",
    "* Sample Submission – Sample format for the submission.\n",
    "\n",
    "![Alt text](https://www.machinehack.com/wp-content/uploads/2020/06/sample.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Required Number of Libraries\n",
    "#Importing Required Libraries\n",
    "#_______________________________________________________________________________________________________________\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as style # for styling the graphs\n",
    "#_______________________________________________________________________________________________________________\n",
    "# style.available (to know the available list of styles)\n",
    "style.use('ggplot') # chosen style\n",
    "plt.rc('xtick',labelsize=13) # to globally set the tick size\n",
    "plt.rc('ytick',labelsize=13) # to globally set the tick size\n",
    "# To print multiple outputs together\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "# Change column display number during print\n",
    "pd.set_option('display.max_columns', 500)\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# To display float with 2 decimal, avoid scientific printing\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "# To display float with 2 decimal, avoid scientific printing\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.linear_model import LinearRegression,Lasso,Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "#from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "#from reg_resampler import resampler\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='./enc_train.csv'\n",
    "path1='./enc_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Product_Brand_counts</th>\n",
       "      <th>Item_Category_counts</th>\n",
       "      <th>Subcategory_1_counts</th>\n",
       "      <th>Subcategory_2_counts</th>\n",
       "      <th>month_counts</th>\n",
       "      <th>day_counts</th>\n",
       "      <th>year_counts</th>\n",
       "      <th>Item_Rating_counts</th>\n",
       "      <th>Luggage_counts</th>\n",
       "      <th>Mens_Clothing_counts</th>\n",
       "      <th>Womens_Clothing_counts</th>\n",
       "      <th>Kids_clothing_counts</th>\n",
       "      <th>Personal_care_counts</th>\n",
       "      <th>Electronics_accesories_counts</th>\n",
       "      <th>Home_Accessories_counts</th>\n",
       "      <th>Footwear_counts</th>\n",
       "      <th>automotive_counts</th>\n",
       "      <th>sports_counts</th>\n",
       "      <th>others_counts</th>\n",
       "      <th>Product_Brand_counts_enc</th>\n",
       "      <th>Item_Category_counts_enc</th>\n",
       "      <th>Subcategory_1_counts_enc</th>\n",
       "      <th>Subcategory_2_counts_enc</th>\n",
       "      <th>month_counts_enc</th>\n",
       "      <th>day_counts_enc</th>\n",
       "      <th>year_counts_enc</th>\n",
       "      <th>Item_Rating_counts_enc</th>\n",
       "      <th>Luggage_counts_enc</th>\n",
       "      <th>Mens_Clothing_counts_enc</th>\n",
       "      <th>Womens_Clothing_counts_enc</th>\n",
       "      <th>Kids_clothing_counts_enc</th>\n",
       "      <th>Personal_care_counts_enc</th>\n",
       "      <th>Electronics_accesories_counts_enc</th>\n",
       "      <th>Home_Accessories_counts_enc</th>\n",
       "      <th>Footwear_counts_enc</th>\n",
       "      <th>automotive_counts_enc</th>\n",
       "      <th>sports_counts_enc</th>\n",
       "      <th>others_counts_enc</th>\n",
       "      <th>Selling_Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>27</td>\n",
       "      <td>13</td>\n",
       "      <td>85</td>\n",
       "      <td>335</td>\n",
       "      <td>319</td>\n",
       "      <td>71</td>\n",
       "      <td>38</td>\n",
       "      <td>2273</td>\n",
       "      <td>1963</td>\n",
       "      <td>2364</td>\n",
       "      <td>1924</td>\n",
       "      <td>2198</td>\n",
       "      <td>2132</td>\n",
       "      <td>2290</td>\n",
       "      <td>2262</td>\n",
       "      <td>2426</td>\n",
       "      <td>2410</td>\n",
       "      <td>1624.72</td>\n",
       "      <td>1252.13</td>\n",
       "      <td>939.70</td>\n",
       "      <td>1198.42</td>\n",
       "      <td>1239.35</td>\n",
       "      <td>2374.28</td>\n",
       "      <td>2931.92</td>\n",
       "      <td>1583.96</td>\n",
       "      <td>1654.10</td>\n",
       "      <td>2688.42</td>\n",
       "      <td>2998.54</td>\n",
       "      <td>2603.19</td>\n",
       "      <td>1338.13</td>\n",
       "      <td>2616.36</td>\n",
       "      <td>2780.43</td>\n",
       "      <td>2637.24</td>\n",
       "      <td>2665.42</td>\n",
       "      <td>2551.28</td>\n",
       "      <td>2570.36</td>\n",
       "      <td>291.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>688</td>\n",
       "      <td>717</td>\n",
       "      <td>476</td>\n",
       "      <td>267</td>\n",
       "      <td>296</td>\n",
       "      <td>349</td>\n",
       "      <td>313</td>\n",
       "      <td>67</td>\n",
       "      <td>2414</td>\n",
       "      <td>2273</td>\n",
       "      <td>489</td>\n",
       "      <td>2364</td>\n",
       "      <td>1924</td>\n",
       "      <td>2198</td>\n",
       "      <td>2132</td>\n",
       "      <td>2290</td>\n",
       "      <td>2262</td>\n",
       "      <td>2426</td>\n",
       "      <td>2410</td>\n",
       "      <td>812.25</td>\n",
       "      <td>690.94</td>\n",
       "      <td>612.03</td>\n",
       "      <td>635.52</td>\n",
       "      <td>1093.28</td>\n",
       "      <td>4345.40</td>\n",
       "      <td>3035.92</td>\n",
       "      <td>2989.41</td>\n",
       "      <td>2668.47</td>\n",
       "      <td>2792.87</td>\n",
       "      <td>611.25</td>\n",
       "      <td>2721.71</td>\n",
       "      <td>1401.73</td>\n",
       "      <td>2735.09</td>\n",
       "      <td>2881.01</td>\n",
       "      <td>2769.03</td>\n",
       "      <td>2785.11</td>\n",
       "      <td>2662.75</td>\n",
       "      <td>2683.55</td>\n",
       "      <td>897.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>98</td>\n",
       "      <td>35</td>\n",
       "      <td>14</td>\n",
       "      <td>773</td>\n",
       "      <td>407</td>\n",
       "      <td>308</td>\n",
       "      <td>63</td>\n",
       "      <td>2414</td>\n",
       "      <td>2273</td>\n",
       "      <td>1963</td>\n",
       "      <td>2364</td>\n",
       "      <td>1924</td>\n",
       "      <td>2198</td>\n",
       "      <td>101</td>\n",
       "      <td>2290</td>\n",
       "      <td>2262</td>\n",
       "      <td>2426</td>\n",
       "      <td>2410</td>\n",
       "      <td>2195.02</td>\n",
       "      <td>1950.81</td>\n",
       "      <td>1809.12</td>\n",
       "      <td>900.35</td>\n",
       "      <td>4291.09</td>\n",
       "      <td>1420.36</td>\n",
       "      <td>2233.10</td>\n",
       "      <td>2505.35</td>\n",
       "      <td>2430.06</td>\n",
       "      <td>2551.36</td>\n",
       "      <td>2841.22</td>\n",
       "      <td>2481.51</td>\n",
       "      <td>1325.97</td>\n",
       "      <td>2490.56</td>\n",
       "      <td>1918.37</td>\n",
       "      <td>2523.20</td>\n",
       "      <td>2528.04</td>\n",
       "      <td>2421.93</td>\n",
       "      <td>2445.75</td>\n",
       "      <td>792.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>688</td>\n",
       "      <td>90</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>598</td>\n",
       "      <td>335</td>\n",
       "      <td>310</td>\n",
       "      <td>92</td>\n",
       "      <td>2414</td>\n",
       "      <td>2273</td>\n",
       "      <td>1963</td>\n",
       "      <td>2364</td>\n",
       "      <td>90</td>\n",
       "      <td>2198</td>\n",
       "      <td>2132</td>\n",
       "      <td>2290</td>\n",
       "      <td>2262</td>\n",
       "      <td>2426</td>\n",
       "      <td>2410</td>\n",
       "      <td>794.19</td>\n",
       "      <td>596.66</td>\n",
       "      <td>3294.82</td>\n",
       "      <td>1982.73</td>\n",
       "      <td>1479.45</td>\n",
       "      <td>2374.28</td>\n",
       "      <td>2322.81</td>\n",
       "      <td>2178.16</td>\n",
       "      <td>2557.92</td>\n",
       "      <td>2688.42</td>\n",
       "      <td>2998.54</td>\n",
       "      <td>2603.19</td>\n",
       "      <td>596.66</td>\n",
       "      <td>2616.36</td>\n",
       "      <td>2780.43</td>\n",
       "      <td>2637.24</td>\n",
       "      <td>2665.42</td>\n",
       "      <td>2551.28</td>\n",
       "      <td>2570.36</td>\n",
       "      <td>837.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>688</td>\n",
       "      <td>717</td>\n",
       "      <td>174</td>\n",
       "      <td>61</td>\n",
       "      <td>598</td>\n",
       "      <td>331</td>\n",
       "      <td>289</td>\n",
       "      <td>71</td>\n",
       "      <td>2414</td>\n",
       "      <td>179</td>\n",
       "      <td>1963</td>\n",
       "      <td>2364</td>\n",
       "      <td>1924</td>\n",
       "      <td>2198</td>\n",
       "      <td>2132</td>\n",
       "      <td>2290</td>\n",
       "      <td>2262</td>\n",
       "      <td>2426</td>\n",
       "      <td>2410</td>\n",
       "      <td>812.25</td>\n",
       "      <td>690.94</td>\n",
       "      <td>853.57</td>\n",
       "      <td>536.58</td>\n",
       "      <td>1672.51</td>\n",
       "      <td>3036.36</td>\n",
       "      <td>2592.53</td>\n",
       "      <td>1283.98</td>\n",
       "      <td>2668.47</td>\n",
       "      <td>841.77</td>\n",
       "      <td>3175.88</td>\n",
       "      <td>2721.71</td>\n",
       "      <td>1401.73</td>\n",
       "      <td>2735.09</td>\n",
       "      <td>2881.01</td>\n",
       "      <td>2769.03</td>\n",
       "      <td>2785.11</td>\n",
       "      <td>2662.75</td>\n",
       "      <td>2683.55</td>\n",
       "      <td>470.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2447</th>\n",
       "      <td>2447</td>\n",
       "      <td>2447</td>\n",
       "      <td>1</td>\n",
       "      <td>717</td>\n",
       "      <td>67</td>\n",
       "      <td>40</td>\n",
       "      <td>41</td>\n",
       "      <td>335</td>\n",
       "      <td>319</td>\n",
       "      <td>56</td>\n",
       "      <td>2414</td>\n",
       "      <td>2273</td>\n",
       "      <td>1963</td>\n",
       "      <td>88</td>\n",
       "      <td>1924</td>\n",
       "      <td>2198</td>\n",
       "      <td>2132</td>\n",
       "      <td>2290</td>\n",
       "      <td>2262</td>\n",
       "      <td>2426</td>\n",
       "      <td>2410</td>\n",
       "      <td>1481.45</td>\n",
       "      <td>699.41</td>\n",
       "      <td>813.16</td>\n",
       "      <td>894.11</td>\n",
       "      <td>4979.77</td>\n",
       "      <td>2036.17</td>\n",
       "      <td>2452.51</td>\n",
       "      <td>1325.02</td>\n",
       "      <td>2507.44</td>\n",
       "      <td>2621.03</td>\n",
       "      <td>2974.19</td>\n",
       "      <td>794.99</td>\n",
       "      <td>1320.80</td>\n",
       "      <td>2540.66</td>\n",
       "      <td>2719.29</td>\n",
       "      <td>2595.59</td>\n",
       "      <td>2605.40</td>\n",
       "      <td>2494.48</td>\n",
       "      <td>2524.16</td>\n",
       "      <td>741.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2448</th>\n",
       "      <td>2448</td>\n",
       "      <td>2448</td>\n",
       "      <td>688</td>\n",
       "      <td>161</td>\n",
       "      <td>101</td>\n",
       "      <td>70</td>\n",
       "      <td>162</td>\n",
       "      <td>322</td>\n",
       "      <td>285</td>\n",
       "      <td>50</td>\n",
       "      <td>2414</td>\n",
       "      <td>2273</td>\n",
       "      <td>1963</td>\n",
       "      <td>2364</td>\n",
       "      <td>1924</td>\n",
       "      <td>2198</td>\n",
       "      <td>2132</td>\n",
       "      <td>162</td>\n",
       "      <td>2262</td>\n",
       "      <td>2426</td>\n",
       "      <td>2410</td>\n",
       "      <td>794.19</td>\n",
       "      <td>1109.33</td>\n",
       "      <td>959.20</td>\n",
       "      <td>1394.91</td>\n",
       "      <td>1281.61</td>\n",
       "      <td>2679.17</td>\n",
       "      <td>2761.13</td>\n",
       "      <td>1850.38</td>\n",
       "      <td>2557.92</td>\n",
       "      <td>2688.42</td>\n",
       "      <td>2998.54</td>\n",
       "      <td>2603.19</td>\n",
       "      <td>1338.13</td>\n",
       "      <td>2616.36</td>\n",
       "      <td>2780.43</td>\n",
       "      <td>1109.33</td>\n",
       "      <td>2665.42</td>\n",
       "      <td>2551.28</td>\n",
       "      <td>2570.36</td>\n",
       "      <td>1590.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2449</th>\n",
       "      <td>2449</td>\n",
       "      <td>2449</td>\n",
       "      <td>1</td>\n",
       "      <td>717</td>\n",
       "      <td>174</td>\n",
       "      <td>61</td>\n",
       "      <td>162</td>\n",
       "      <td>335</td>\n",
       "      <td>308</td>\n",
       "      <td>50</td>\n",
       "      <td>2414</td>\n",
       "      <td>179</td>\n",
       "      <td>1963</td>\n",
       "      <td>2364</td>\n",
       "      <td>1924</td>\n",
       "      <td>2198</td>\n",
       "      <td>2132</td>\n",
       "      <td>2290</td>\n",
       "      <td>2262</td>\n",
       "      <td>2426</td>\n",
       "      <td>2410</td>\n",
       "      <td>1213.60</td>\n",
       "      <td>680.20</td>\n",
       "      <td>814.71</td>\n",
       "      <td>495.28</td>\n",
       "      <td>1219.04</td>\n",
       "      <td>2041.20</td>\n",
       "      <td>2355.82</td>\n",
       "      <td>2032.79</td>\n",
       "      <td>2364.40</td>\n",
       "      <td>802.69</td>\n",
       "      <td>2807.27</td>\n",
       "      <td>2416.28</td>\n",
       "      <td>1184.67</td>\n",
       "      <td>2469.50</td>\n",
       "      <td>2576.30</td>\n",
       "      <td>2450.58</td>\n",
       "      <td>2453.24</td>\n",
       "      <td>2360.24</td>\n",
       "      <td>2383.54</td>\n",
       "      <td>995.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2450</th>\n",
       "      <td>2450</td>\n",
       "      <td>2450</td>\n",
       "      <td>91</td>\n",
       "      <td>188</td>\n",
       "      <td>173</td>\n",
       "      <td>126</td>\n",
       "      <td>773</td>\n",
       "      <td>338</td>\n",
       "      <td>310</td>\n",
       "      <td>60</td>\n",
       "      <td>2414</td>\n",
       "      <td>2273</td>\n",
       "      <td>1963</td>\n",
       "      <td>2364</td>\n",
       "      <td>1924</td>\n",
       "      <td>2198</td>\n",
       "      <td>2132</td>\n",
       "      <td>2290</td>\n",
       "      <td>189</td>\n",
       "      <td>2426</td>\n",
       "      <td>2410</td>\n",
       "      <td>1447.29</td>\n",
       "      <td>1129.61</td>\n",
       "      <td>1149.34</td>\n",
       "      <td>1352.05</td>\n",
       "      <td>4291.09</td>\n",
       "      <td>2787.17</td>\n",
       "      <td>2621.95</td>\n",
       "      <td>1812.34</td>\n",
       "      <td>2430.06</td>\n",
       "      <td>2551.36</td>\n",
       "      <td>2841.22</td>\n",
       "      <td>2481.51</td>\n",
       "      <td>1325.97</td>\n",
       "      <td>2490.56</td>\n",
       "      <td>2620.09</td>\n",
       "      <td>2523.20</td>\n",
       "      <td>1164.14</td>\n",
       "      <td>2421.93</td>\n",
       "      <td>2445.75</td>\n",
       "      <td>1598.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2451</th>\n",
       "      <td>2451</td>\n",
       "      <td>2451</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>167</td>\n",
       "      <td>338</td>\n",
       "      <td>308</td>\n",
       "      <td>60</td>\n",
       "      <td>38</td>\n",
       "      <td>2273</td>\n",
       "      <td>1963</td>\n",
       "      <td>2364</td>\n",
       "      <td>1924</td>\n",
       "      <td>2198</td>\n",
       "      <td>2132</td>\n",
       "      <td>2290</td>\n",
       "      <td>2262</td>\n",
       "      <td>2426</td>\n",
       "      <td>2410</td>\n",
       "      <td>1556.44</td>\n",
       "      <td>1267.16</td>\n",
       "      <td>1391.82</td>\n",
       "      <td>799.92</td>\n",
       "      <td>1477.10</td>\n",
       "      <td>2787.17</td>\n",
       "      <td>2233.10</td>\n",
       "      <td>1812.34</td>\n",
       "      <td>1721.43</td>\n",
       "      <td>2551.36</td>\n",
       "      <td>2841.22</td>\n",
       "      <td>2481.51</td>\n",
       "      <td>1325.97</td>\n",
       "      <td>2490.56</td>\n",
       "      <td>2620.09</td>\n",
       "      <td>2523.20</td>\n",
       "      <td>2528.04</td>\n",
       "      <td>2421.93</td>\n",
       "      <td>2445.75</td>\n",
       "      <td>397.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2452 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  Unnamed: 0.1  Product_Brand_counts  Item_Category_counts  \\\n",
       "0              0             0                     1                    38   \n",
       "1              1             1                   688                   717   \n",
       "2              2             2                     2                    98   \n",
       "3              3             3                   688                    90   \n",
       "4              4             4                   688                   717   \n",
       "...          ...           ...                   ...                   ...   \n",
       "2447        2447          2447                     1                   717   \n",
       "2448        2448          2448                   688                   161   \n",
       "2449        2449          2449                     1                   717   \n",
       "2450        2450          2450                    91                   188   \n",
       "2451        2451          2451                     1                    38   \n",
       "\n",
       "      Subcategory_1_counts  Subcategory_2_counts  month_counts  day_counts  \\\n",
       "0                       27                    13            85         335   \n",
       "1                      476                   267           296         349   \n",
       "2                       35                    14           773         407   \n",
       "3                        2                     1           598         335   \n",
       "4                      174                    61           598         331   \n",
       "...                    ...                   ...           ...         ...   \n",
       "2447                    67                    40            41         335   \n",
       "2448                   101                    70           162         322   \n",
       "2449                   174                    61           162         335   \n",
       "2450                   173                   126           773         338   \n",
       "2451                    27                     2           167         338   \n",
       "\n",
       "      year_counts  Item_Rating_counts  Luggage_counts  Mens_Clothing_counts  \\\n",
       "0             319                  71              38                  2273   \n",
       "1             313                  67            2414                  2273   \n",
       "2             308                  63            2414                  2273   \n",
       "3             310                  92            2414                  2273   \n",
       "4             289                  71            2414                   179   \n",
       "...           ...                 ...             ...                   ...   \n",
       "2447          319                  56            2414                  2273   \n",
       "2448          285                  50            2414                  2273   \n",
       "2449          308                  50            2414                   179   \n",
       "2450          310                  60            2414                  2273   \n",
       "2451          308                  60              38                  2273   \n",
       "\n",
       "      Womens_Clothing_counts  Kids_clothing_counts  Personal_care_counts  \\\n",
       "0                       1963                  2364                  1924   \n",
       "1                        489                  2364                  1924   \n",
       "2                       1963                  2364                  1924   \n",
       "3                       1963                  2364                    90   \n",
       "4                       1963                  2364                  1924   \n",
       "...                      ...                   ...                   ...   \n",
       "2447                    1963                    88                  1924   \n",
       "2448                    1963                  2364                  1924   \n",
       "2449                    1963                  2364                  1924   \n",
       "2450                    1963                  2364                  1924   \n",
       "2451                    1963                  2364                  1924   \n",
       "\n",
       "      Electronics_accesories_counts  Home_Accessories_counts  Footwear_counts  \\\n",
       "0                              2198                     2132             2290   \n",
       "1                              2198                     2132             2290   \n",
       "2                              2198                      101             2290   \n",
       "3                              2198                     2132             2290   \n",
       "4                              2198                     2132             2290   \n",
       "...                             ...                      ...              ...   \n",
       "2447                           2198                     2132             2290   \n",
       "2448                           2198                     2132              162   \n",
       "2449                           2198                     2132             2290   \n",
       "2450                           2198                     2132             2290   \n",
       "2451                           2198                     2132             2290   \n",
       "\n",
       "      automotive_counts  sports_counts  others_counts  \\\n",
       "0                  2262           2426           2410   \n",
       "1                  2262           2426           2410   \n",
       "2                  2262           2426           2410   \n",
       "3                  2262           2426           2410   \n",
       "4                  2262           2426           2410   \n",
       "...                 ...            ...            ...   \n",
       "2447               2262           2426           2410   \n",
       "2448               2262           2426           2410   \n",
       "2449               2262           2426           2410   \n",
       "2450                189           2426           2410   \n",
       "2451               2262           2426           2410   \n",
       "\n",
       "      Product_Brand_counts_enc  Item_Category_counts_enc  \\\n",
       "0                      1624.72                   1252.13   \n",
       "1                       812.25                    690.94   \n",
       "2                      2195.02                   1950.81   \n",
       "3                       794.19                    596.66   \n",
       "4                       812.25                    690.94   \n",
       "...                        ...                       ...   \n",
       "2447                   1481.45                    699.41   \n",
       "2448                    794.19                   1109.33   \n",
       "2449                   1213.60                    680.20   \n",
       "2450                   1447.29                   1129.61   \n",
       "2451                   1556.44                   1267.16   \n",
       "\n",
       "      Subcategory_1_counts_enc  Subcategory_2_counts_enc  month_counts_enc  \\\n",
       "0                       939.70                   1198.42           1239.35   \n",
       "1                       612.03                    635.52           1093.28   \n",
       "2                      1809.12                    900.35           4291.09   \n",
       "3                      3294.82                   1982.73           1479.45   \n",
       "4                       853.57                    536.58           1672.51   \n",
       "...                        ...                       ...               ...   \n",
       "2447                    813.16                    894.11           4979.77   \n",
       "2448                    959.20                   1394.91           1281.61   \n",
       "2449                    814.71                    495.28           1219.04   \n",
       "2450                   1149.34                   1352.05           4291.09   \n",
       "2451                   1391.82                    799.92           1477.10   \n",
       "\n",
       "      day_counts_enc  year_counts_enc  Item_Rating_counts_enc  \\\n",
       "0            2374.28          2931.92                 1583.96   \n",
       "1            4345.40          3035.92                 2989.41   \n",
       "2            1420.36          2233.10                 2505.35   \n",
       "3            2374.28          2322.81                 2178.16   \n",
       "4            3036.36          2592.53                 1283.98   \n",
       "...              ...              ...                     ...   \n",
       "2447         2036.17          2452.51                 1325.02   \n",
       "2448         2679.17          2761.13                 1850.38   \n",
       "2449         2041.20          2355.82                 2032.79   \n",
       "2450         2787.17          2621.95                 1812.34   \n",
       "2451         2787.17          2233.10                 1812.34   \n",
       "\n",
       "      Luggage_counts_enc  Mens_Clothing_counts_enc  \\\n",
       "0                1654.10                   2688.42   \n",
       "1                2668.47                   2792.87   \n",
       "2                2430.06                   2551.36   \n",
       "3                2557.92                   2688.42   \n",
       "4                2668.47                    841.77   \n",
       "...                  ...                       ...   \n",
       "2447             2507.44                   2621.03   \n",
       "2448             2557.92                   2688.42   \n",
       "2449             2364.40                    802.69   \n",
       "2450             2430.06                   2551.36   \n",
       "2451             1721.43                   2551.36   \n",
       "\n",
       "      Womens_Clothing_counts_enc  Kids_clothing_counts_enc  \\\n",
       "0                        2998.54                   2603.19   \n",
       "1                         611.25                   2721.71   \n",
       "2                        2841.22                   2481.51   \n",
       "3                        2998.54                   2603.19   \n",
       "4                        3175.88                   2721.71   \n",
       "...                          ...                       ...   \n",
       "2447                     2974.19                    794.99   \n",
       "2448                     2998.54                   2603.19   \n",
       "2449                     2807.27                   2416.28   \n",
       "2450                     2841.22                   2481.51   \n",
       "2451                     2841.22                   2481.51   \n",
       "\n",
       "      Personal_care_counts_enc  Electronics_accesories_counts_enc  \\\n",
       "0                      1338.13                            2616.36   \n",
       "1                      1401.73                            2735.09   \n",
       "2                      1325.97                            2490.56   \n",
       "3                       596.66                            2616.36   \n",
       "4                      1401.73                            2735.09   \n",
       "...                        ...                                ...   \n",
       "2447                   1320.80                            2540.66   \n",
       "2448                   1338.13                            2616.36   \n",
       "2449                   1184.67                            2469.50   \n",
       "2450                   1325.97                            2490.56   \n",
       "2451                   1325.97                            2490.56   \n",
       "\n",
       "      Home_Accessories_counts_enc  Footwear_counts_enc  automotive_counts_enc  \\\n",
       "0                         2780.43              2637.24                2665.42   \n",
       "1                         2881.01              2769.03                2785.11   \n",
       "2                         1918.37              2523.20                2528.04   \n",
       "3                         2780.43              2637.24                2665.42   \n",
       "4                         2881.01              2769.03                2785.11   \n",
       "...                           ...                  ...                    ...   \n",
       "2447                      2719.29              2595.59                2605.40   \n",
       "2448                      2780.43              1109.33                2665.42   \n",
       "2449                      2576.30              2450.58                2453.24   \n",
       "2450                      2620.09              2523.20                1164.14   \n",
       "2451                      2620.09              2523.20                2528.04   \n",
       "\n",
       "      sports_counts_enc  others_counts_enc  Selling_Price  \n",
       "0               2551.28            2570.36         291.00  \n",
       "1               2662.75            2683.55         897.00  \n",
       "2               2421.93            2445.75         792.00  \n",
       "3               2551.28            2570.36         837.00  \n",
       "4               2662.75            2683.55         470.00  \n",
       "...                 ...                ...            ...  \n",
       "2447            2494.48            2524.16         741.00  \n",
       "2448            2551.28            2570.36        1590.00  \n",
       "2449            2360.24            2383.54         995.00  \n",
       "2450            2421.93            2445.75        1598.00  \n",
       "2451            2421.93            2445.75         397.00  \n",
       "\n",
       "[2452 rows x 41 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=pd.read_csv(path)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Product_Brand_counts</th>\n",
       "      <th>Item_Category_counts</th>\n",
       "      <th>Subcategory_1_counts</th>\n",
       "      <th>Subcategory_2_counts</th>\n",
       "      <th>month_counts</th>\n",
       "      <th>day_counts</th>\n",
       "      <th>year_counts</th>\n",
       "      <th>Item_Rating_counts</th>\n",
       "      <th>Luggage_counts</th>\n",
       "      <th>Mens_Clothing_counts</th>\n",
       "      <th>Womens_Clothing_counts</th>\n",
       "      <th>Kids_clothing_counts</th>\n",
       "      <th>Personal_care_counts</th>\n",
       "      <th>Electronics_accesories_counts</th>\n",
       "      <th>Home_Accessories_counts</th>\n",
       "      <th>Footwear_counts</th>\n",
       "      <th>automotive_counts</th>\n",
       "      <th>sports_counts</th>\n",
       "      <th>others_counts</th>\n",
       "      <th>Product_Brand_counts_enc</th>\n",
       "      <th>Item_Category_counts_enc</th>\n",
       "      <th>Subcategory_1_counts_enc</th>\n",
       "      <th>Subcategory_2_counts_enc</th>\n",
       "      <th>month_counts_enc</th>\n",
       "      <th>day_counts_enc</th>\n",
       "      <th>year_counts_enc</th>\n",
       "      <th>Item_Rating_counts_enc</th>\n",
       "      <th>Luggage_counts_enc</th>\n",
       "      <th>Mens_Clothing_counts_enc</th>\n",
       "      <th>Womens_Clothing_counts_enc</th>\n",
       "      <th>Kids_clothing_counts_enc</th>\n",
       "      <th>Personal_care_counts_enc</th>\n",
       "      <th>Electronics_accesories_counts_enc</th>\n",
       "      <th>Home_Accessories_counts_enc</th>\n",
       "      <th>Footwear_counts_enc</th>\n",
       "      <th>automotive_counts_enc</th>\n",
       "      <th>sports_counts_enc</th>\n",
       "      <th>others_counts_enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>104.00</td>\n",
       "      <td>42.00</td>\n",
       "      <td>41.00</td>\n",
       "      <td>773</td>\n",
       "      <td>335</td>\n",
       "      <td>316</td>\n",
       "      <td>71</td>\n",
       "      <td>2414</td>\n",
       "      <td>2273</td>\n",
       "      <td>1963</td>\n",
       "      <td>2364</td>\n",
       "      <td>1924</td>\n",
       "      <td>105</td>\n",
       "      <td>2132</td>\n",
       "      <td>2290</td>\n",
       "      <td>2262</td>\n",
       "      <td>2426</td>\n",
       "      <td>2410</td>\n",
       "      <td>2327.96</td>\n",
       "      <td>2125.10</td>\n",
       "      <td>3554.88</td>\n",
       "      <td>3633.63</td>\n",
       "      <td>4508.94</td>\n",
       "      <td>2053.87</td>\n",
       "      <td>1833.62</td>\n",
       "      <td>1662.21</td>\n",
       "      <td>2505.65</td>\n",
       "      <td>2625.53</td>\n",
       "      <td>2959.22</td>\n",
       "      <td>2556.90</td>\n",
       "      <td>1314.31</td>\n",
       "      <td>2115.27</td>\n",
       "      <td>2715.52</td>\n",
       "      <td>2595.25</td>\n",
       "      <td>2607.29</td>\n",
       "      <td>2498.15</td>\n",
       "      <td>2521.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>428.00</td>\n",
       "      <td>77.00</td>\n",
       "      <td>27.00</td>\n",
       "      <td>598</td>\n",
       "      <td>331</td>\n",
       "      <td>147</td>\n",
       "      <td>72</td>\n",
       "      <td>2414</td>\n",
       "      <td>2273</td>\n",
       "      <td>1963</td>\n",
       "      <td>2364</td>\n",
       "      <td>428</td>\n",
       "      <td>2198</td>\n",
       "      <td>2132</td>\n",
       "      <td>2290</td>\n",
       "      <td>2262</td>\n",
       "      <td>2426</td>\n",
       "      <td>2410</td>\n",
       "      <td>1484.64</td>\n",
       "      <td>8238.70</td>\n",
       "      <td>952.96</td>\n",
       "      <td>1646.00</td>\n",
       "      <td>1491.01</td>\n",
       "      <td>2829.76</td>\n",
       "      <td>2218.28</td>\n",
       "      <td>3144.28</td>\n",
       "      <td>2505.65</td>\n",
       "      <td>2625.53</td>\n",
       "      <td>2959.22</td>\n",
       "      <td>2556.90</td>\n",
       "      <td>8238.70</td>\n",
       "      <td>2570.30</td>\n",
       "      <td>2715.52</td>\n",
       "      <td>2595.25</td>\n",
       "      <td>2607.29</td>\n",
       "      <td>2498.15</td>\n",
       "      <td>2521.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>688.00</td>\n",
       "      <td>717.00</td>\n",
       "      <td>476.00</td>\n",
       "      <td>267.00</td>\n",
       "      <td>773</td>\n",
       "      <td>338</td>\n",
       "      <td>310</td>\n",
       "      <td>62</td>\n",
       "      <td>2414</td>\n",
       "      <td>2273</td>\n",
       "      <td>489</td>\n",
       "      <td>2364</td>\n",
       "      <td>1924</td>\n",
       "      <td>2198</td>\n",
       "      <td>2132</td>\n",
       "      <td>2290</td>\n",
       "      <td>2262</td>\n",
       "      <td>2426</td>\n",
       "      <td>2410</td>\n",
       "      <td>780.78</td>\n",
       "      <td>701.52</td>\n",
       "      <td>630.24</td>\n",
       "      <td>639.85</td>\n",
       "      <td>4508.94</td>\n",
       "      <td>2782.97</td>\n",
       "      <td>2490.04</td>\n",
       "      <td>2210.85</td>\n",
       "      <td>2505.65</td>\n",
       "      <td>2625.53</td>\n",
       "      <td>628.35</td>\n",
       "      <td>2556.90</td>\n",
       "      <td>1314.31</td>\n",
       "      <td>2570.30</td>\n",
       "      <td>2715.52</td>\n",
       "      <td>2595.25</td>\n",
       "      <td>2607.29</td>\n",
       "      <td>2498.15</td>\n",
       "      <td>2521.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4.00</td>\n",
       "      <td>428.00</td>\n",
       "      <td>160.00</td>\n",
       "      <td>158.00</td>\n",
       "      <td>773</td>\n",
       "      <td>407</td>\n",
       "      <td>308</td>\n",
       "      <td>53</td>\n",
       "      <td>2414</td>\n",
       "      <td>2273</td>\n",
       "      <td>1963</td>\n",
       "      <td>2364</td>\n",
       "      <td>428</td>\n",
       "      <td>2198</td>\n",
       "      <td>2132</td>\n",
       "      <td>2290</td>\n",
       "      <td>2262</td>\n",
       "      <td>2426</td>\n",
       "      <td>2410</td>\n",
       "      <td>924.66</td>\n",
       "      <td>8238.70</td>\n",
       "      <td>514.04</td>\n",
       "      <td>511.63</td>\n",
       "      <td>4508.94</td>\n",
       "      <td>1363.85</td>\n",
       "      <td>2347.75</td>\n",
       "      <td>2380.16</td>\n",
       "      <td>2505.65</td>\n",
       "      <td>2625.53</td>\n",
       "      <td>2959.22</td>\n",
       "      <td>2556.90</td>\n",
       "      <td>8238.70</td>\n",
       "      <td>2570.30</td>\n",
       "      <td>2715.52</td>\n",
       "      <td>2595.25</td>\n",
       "      <td>2607.29</td>\n",
       "      <td>2498.15</td>\n",
       "      <td>2521.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>688.00</td>\n",
       "      <td>717.00</td>\n",
       "      <td>476.00</td>\n",
       "      <td>267.00</td>\n",
       "      <td>773</td>\n",
       "      <td>331</td>\n",
       "      <td>319</td>\n",
       "      <td>51</td>\n",
       "      <td>2414</td>\n",
       "      <td>2273</td>\n",
       "      <td>489</td>\n",
       "      <td>2364</td>\n",
       "      <td>1924</td>\n",
       "      <td>2198</td>\n",
       "      <td>2132</td>\n",
       "      <td>2290</td>\n",
       "      <td>2262</td>\n",
       "      <td>2426</td>\n",
       "      <td>2410</td>\n",
       "      <td>780.78</td>\n",
       "      <td>701.52</td>\n",
       "      <td>630.24</td>\n",
       "      <td>639.85</td>\n",
       "      <td>4508.94</td>\n",
       "      <td>2829.76</td>\n",
       "      <td>2492.96</td>\n",
       "      <td>1858.47</td>\n",
       "      <td>2505.65</td>\n",
       "      <td>2625.53</td>\n",
       "      <td>628.35</td>\n",
       "      <td>2556.90</td>\n",
       "      <td>1314.31</td>\n",
       "      <td>2570.30</td>\n",
       "      <td>2715.52</td>\n",
       "      <td>2595.25</td>\n",
       "      <td>2607.29</td>\n",
       "      <td>2498.15</td>\n",
       "      <td>2521.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1046</th>\n",
       "      <td>1046</td>\n",
       "      <td>1046</td>\n",
       "      <td>1.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>85</td>\n",
       "      <td>335</td>\n",
       "      <td>310</td>\n",
       "      <td>70</td>\n",
       "      <td>2414</td>\n",
       "      <td>2273</td>\n",
       "      <td>1963</td>\n",
       "      <td>2364</td>\n",
       "      <td>1924</td>\n",
       "      <td>2198</td>\n",
       "      <td>2132</td>\n",
       "      <td>2290</td>\n",
       "      <td>2262</td>\n",
       "      <td>26</td>\n",
       "      <td>2410</td>\n",
       "      <td>1484.64</td>\n",
       "      <td>2246.42</td>\n",
       "      <td>1714.34</td>\n",
       "      <td>1336.75</td>\n",
       "      <td>1216.20</td>\n",
       "      <td>2053.87</td>\n",
       "      <td>2490.04</td>\n",
       "      <td>2698.66</td>\n",
       "      <td>2505.65</td>\n",
       "      <td>2625.53</td>\n",
       "      <td>2959.22</td>\n",
       "      <td>2556.90</td>\n",
       "      <td>1314.31</td>\n",
       "      <td>2570.30</td>\n",
       "      <td>2715.52</td>\n",
       "      <td>2595.25</td>\n",
       "      <td>2607.29</td>\n",
       "      <td>2142.12</td>\n",
       "      <td>2521.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047</th>\n",
       "      <td>1047</td>\n",
       "      <td>1047</td>\n",
       "      <td>14.00</td>\n",
       "      <td>428.00</td>\n",
       "      <td>160.00</td>\n",
       "      <td>158.00</td>\n",
       "      <td>773</td>\n",
       "      <td>407</td>\n",
       "      <td>308</td>\n",
       "      <td>58</td>\n",
       "      <td>2414</td>\n",
       "      <td>2273</td>\n",
       "      <td>1963</td>\n",
       "      <td>2364</td>\n",
       "      <td>428</td>\n",
       "      <td>2198</td>\n",
       "      <td>2132</td>\n",
       "      <td>2290</td>\n",
       "      <td>2262</td>\n",
       "      <td>2426</td>\n",
       "      <td>2410</td>\n",
       "      <td>2347.93</td>\n",
       "      <td>8238.70</td>\n",
       "      <td>514.04</td>\n",
       "      <td>511.63</td>\n",
       "      <td>4508.94</td>\n",
       "      <td>1363.85</td>\n",
       "      <td>2347.75</td>\n",
       "      <td>3884.35</td>\n",
       "      <td>2505.65</td>\n",
       "      <td>2625.53</td>\n",
       "      <td>2959.22</td>\n",
       "      <td>2556.90</td>\n",
       "      <td>8238.70</td>\n",
       "      <td>2570.30</td>\n",
       "      <td>2715.52</td>\n",
       "      <td>2595.25</td>\n",
       "      <td>2607.29</td>\n",
       "      <td>2498.15</td>\n",
       "      <td>2521.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048</th>\n",
       "      <td>1048</td>\n",
       "      <td>1048</td>\n",
       "      <td>91.00</td>\n",
       "      <td>188.00</td>\n",
       "      <td>173.00</td>\n",
       "      <td>126.00</td>\n",
       "      <td>773</td>\n",
       "      <td>338</td>\n",
       "      <td>310</td>\n",
       "      <td>63</td>\n",
       "      <td>2414</td>\n",
       "      <td>2273</td>\n",
       "      <td>1963</td>\n",
       "      <td>2364</td>\n",
       "      <td>1924</td>\n",
       "      <td>2198</td>\n",
       "      <td>2132</td>\n",
       "      <td>2290</td>\n",
       "      <td>189</td>\n",
       "      <td>2426</td>\n",
       "      <td>2410</td>\n",
       "      <td>1410.57</td>\n",
       "      <td>1125.40</td>\n",
       "      <td>1147.24</td>\n",
       "      <td>1330.56</td>\n",
       "      <td>4508.94</td>\n",
       "      <td>2782.97</td>\n",
       "      <td>2490.04</td>\n",
       "      <td>2248.06</td>\n",
       "      <td>2505.65</td>\n",
       "      <td>2625.53</td>\n",
       "      <td>2959.22</td>\n",
       "      <td>2556.90</td>\n",
       "      <td>1314.31</td>\n",
       "      <td>2570.30</td>\n",
       "      <td>2715.52</td>\n",
       "      <td>2595.25</td>\n",
       "      <td>1153.56</td>\n",
       "      <td>2498.15</td>\n",
       "      <td>2521.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>1049</td>\n",
       "      <td>1049</td>\n",
       "      <td>1.00</td>\n",
       "      <td>97.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>181</td>\n",
       "      <td>338</td>\n",
       "      <td>289</td>\n",
       "      <td>62</td>\n",
       "      <td>2414</td>\n",
       "      <td>2273</td>\n",
       "      <td>1963</td>\n",
       "      <td>2364</td>\n",
       "      <td>1924</td>\n",
       "      <td>2198</td>\n",
       "      <td>98</td>\n",
       "      <td>2290</td>\n",
       "      <td>2262</td>\n",
       "      <td>2426</td>\n",
       "      <td>2410</td>\n",
       "      <td>1484.64</td>\n",
       "      <td>406.04</td>\n",
       "      <td>782.53</td>\n",
       "      <td>2584.56</td>\n",
       "      <td>2951.25</td>\n",
       "      <td>2782.97</td>\n",
       "      <td>2439.63</td>\n",
       "      <td>2210.85</td>\n",
       "      <td>2505.65</td>\n",
       "      <td>2625.53</td>\n",
       "      <td>2959.22</td>\n",
       "      <td>2556.90</td>\n",
       "      <td>1314.31</td>\n",
       "      <td>2570.30</td>\n",
       "      <td>426.34</td>\n",
       "      <td>2595.25</td>\n",
       "      <td>2607.29</td>\n",
       "      <td>2498.15</td>\n",
       "      <td>2521.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>1050</td>\n",
       "      <td>1050</td>\n",
       "      <td>91.00</td>\n",
       "      <td>188.00</td>\n",
       "      <td>173.00</td>\n",
       "      <td>126.00</td>\n",
       "      <td>773</td>\n",
       "      <td>331</td>\n",
       "      <td>147</td>\n",
       "      <td>67</td>\n",
       "      <td>2414</td>\n",
       "      <td>2273</td>\n",
       "      <td>1963</td>\n",
       "      <td>2364</td>\n",
       "      <td>1924</td>\n",
       "      <td>2198</td>\n",
       "      <td>2132</td>\n",
       "      <td>2290</td>\n",
       "      <td>189</td>\n",
       "      <td>2426</td>\n",
       "      <td>2410</td>\n",
       "      <td>1410.57</td>\n",
       "      <td>1125.40</td>\n",
       "      <td>1147.24</td>\n",
       "      <td>1330.56</td>\n",
       "      <td>4508.94</td>\n",
       "      <td>2829.76</td>\n",
       "      <td>2218.28</td>\n",
       "      <td>3276.58</td>\n",
       "      <td>2505.65</td>\n",
       "      <td>2625.53</td>\n",
       "      <td>2959.22</td>\n",
       "      <td>2556.90</td>\n",
       "      <td>1314.31</td>\n",
       "      <td>2570.30</td>\n",
       "      <td>2715.52</td>\n",
       "      <td>2595.25</td>\n",
       "      <td>1153.56</td>\n",
       "      <td>2498.15</td>\n",
       "      <td>2521.49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1051 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  Unnamed: 0.1  Product_Brand_counts  Item_Category_counts  \\\n",
       "0              0             0                  2.00                104.00   \n",
       "1              1             1                  1.00                428.00   \n",
       "2              2             2                688.00                717.00   \n",
       "3              3             3                  4.00                428.00   \n",
       "4              4             4                688.00                717.00   \n",
       "...          ...           ...                   ...                   ...   \n",
       "1046        1046          1046                  1.00                 24.00   \n",
       "1047        1047          1047                 14.00                428.00   \n",
       "1048        1048          1048                 91.00                188.00   \n",
       "1049        1049          1049                  1.00                 97.00   \n",
       "1050        1050          1050                 91.00                188.00   \n",
       "\n",
       "      Subcategory_1_counts  Subcategory_2_counts  month_counts  day_counts  \\\n",
       "0                    42.00                 41.00           773         335   \n",
       "1                    77.00                 27.00           598         331   \n",
       "2                   476.00                267.00           773         338   \n",
       "3                   160.00                158.00           773         407   \n",
       "4                   476.00                267.00           773         331   \n",
       "...                    ...                   ...           ...         ...   \n",
       "1046                  4.00                  3.00            85         335   \n",
       "1047                160.00                158.00           773         407   \n",
       "1048                173.00                126.00           773         338   \n",
       "1049                  5.00                  5.00           181         338   \n",
       "1050                173.00                126.00           773         331   \n",
       "\n",
       "      year_counts  Item_Rating_counts  Luggage_counts  Mens_Clothing_counts  \\\n",
       "0             316                  71            2414                  2273   \n",
       "1             147                  72            2414                  2273   \n",
       "2             310                  62            2414                  2273   \n",
       "3             308                  53            2414                  2273   \n",
       "4             319                  51            2414                  2273   \n",
       "...           ...                 ...             ...                   ...   \n",
       "1046          310                  70            2414                  2273   \n",
       "1047          308                  58            2414                  2273   \n",
       "1048          310                  63            2414                  2273   \n",
       "1049          289                  62            2414                  2273   \n",
       "1050          147                  67            2414                  2273   \n",
       "\n",
       "      Womens_Clothing_counts  Kids_clothing_counts  Personal_care_counts  \\\n",
       "0                       1963                  2364                  1924   \n",
       "1                       1963                  2364                   428   \n",
       "2                        489                  2364                  1924   \n",
       "3                       1963                  2364                   428   \n",
       "4                        489                  2364                  1924   \n",
       "...                      ...                   ...                   ...   \n",
       "1046                    1963                  2364                  1924   \n",
       "1047                    1963                  2364                   428   \n",
       "1048                    1963                  2364                  1924   \n",
       "1049                    1963                  2364                  1924   \n",
       "1050                    1963                  2364                  1924   \n",
       "\n",
       "      Electronics_accesories_counts  Home_Accessories_counts  Footwear_counts  \\\n",
       "0                               105                     2132             2290   \n",
       "1                              2198                     2132             2290   \n",
       "2                              2198                     2132             2290   \n",
       "3                              2198                     2132             2290   \n",
       "4                              2198                     2132             2290   \n",
       "...                             ...                      ...              ...   \n",
       "1046                           2198                     2132             2290   \n",
       "1047                           2198                     2132             2290   \n",
       "1048                           2198                     2132             2290   \n",
       "1049                           2198                       98             2290   \n",
       "1050                           2198                     2132             2290   \n",
       "\n",
       "      automotive_counts  sports_counts  others_counts  \\\n",
       "0                  2262           2426           2410   \n",
       "1                  2262           2426           2410   \n",
       "2                  2262           2426           2410   \n",
       "3                  2262           2426           2410   \n",
       "4                  2262           2426           2410   \n",
       "...                 ...            ...            ...   \n",
       "1046               2262             26           2410   \n",
       "1047               2262           2426           2410   \n",
       "1048                189           2426           2410   \n",
       "1049               2262           2426           2410   \n",
       "1050                189           2426           2410   \n",
       "\n",
       "      Product_Brand_counts_enc  Item_Category_counts_enc  \\\n",
       "0                      2327.96                   2125.10   \n",
       "1                      1484.64                   8238.70   \n",
       "2                       780.78                    701.52   \n",
       "3                       924.66                   8238.70   \n",
       "4                       780.78                    701.52   \n",
       "...                        ...                       ...   \n",
       "1046                   1484.64                   2246.42   \n",
       "1047                   2347.93                   8238.70   \n",
       "1048                   1410.57                   1125.40   \n",
       "1049                   1484.64                    406.04   \n",
       "1050                   1410.57                   1125.40   \n",
       "\n",
       "      Subcategory_1_counts_enc  Subcategory_2_counts_enc  month_counts_enc  \\\n",
       "0                      3554.88                   3633.63           4508.94   \n",
       "1                       952.96                   1646.00           1491.01   \n",
       "2                       630.24                    639.85           4508.94   \n",
       "3                       514.04                    511.63           4508.94   \n",
       "4                       630.24                    639.85           4508.94   \n",
       "...                        ...                       ...               ...   \n",
       "1046                   1714.34                   1336.75           1216.20   \n",
       "1047                    514.04                    511.63           4508.94   \n",
       "1048                   1147.24                   1330.56           4508.94   \n",
       "1049                    782.53                   2584.56           2951.25   \n",
       "1050                   1147.24                   1330.56           4508.94   \n",
       "\n",
       "      day_counts_enc  year_counts_enc  Item_Rating_counts_enc  \\\n",
       "0            2053.87          1833.62                 1662.21   \n",
       "1            2829.76          2218.28                 3144.28   \n",
       "2            2782.97          2490.04                 2210.85   \n",
       "3            1363.85          2347.75                 2380.16   \n",
       "4            2829.76          2492.96                 1858.47   \n",
       "...              ...              ...                     ...   \n",
       "1046         2053.87          2490.04                 2698.66   \n",
       "1047         1363.85          2347.75                 3884.35   \n",
       "1048         2782.97          2490.04                 2248.06   \n",
       "1049         2782.97          2439.63                 2210.85   \n",
       "1050         2829.76          2218.28                 3276.58   \n",
       "\n",
       "      Luggage_counts_enc  Mens_Clothing_counts_enc  \\\n",
       "0                2505.65                   2625.53   \n",
       "1                2505.65                   2625.53   \n",
       "2                2505.65                   2625.53   \n",
       "3                2505.65                   2625.53   \n",
       "4                2505.65                   2625.53   \n",
       "...                  ...                       ...   \n",
       "1046             2505.65                   2625.53   \n",
       "1047             2505.65                   2625.53   \n",
       "1048             2505.65                   2625.53   \n",
       "1049             2505.65                   2625.53   \n",
       "1050             2505.65                   2625.53   \n",
       "\n",
       "      Womens_Clothing_counts_enc  Kids_clothing_counts_enc  \\\n",
       "0                        2959.22                   2556.90   \n",
       "1                        2959.22                   2556.90   \n",
       "2                         628.35                   2556.90   \n",
       "3                        2959.22                   2556.90   \n",
       "4                         628.35                   2556.90   \n",
       "...                          ...                       ...   \n",
       "1046                     2959.22                   2556.90   \n",
       "1047                     2959.22                   2556.90   \n",
       "1048                     2959.22                   2556.90   \n",
       "1049                     2959.22                   2556.90   \n",
       "1050                     2959.22                   2556.90   \n",
       "\n",
       "      Personal_care_counts_enc  Electronics_accesories_counts_enc  \\\n",
       "0                      1314.31                            2115.27   \n",
       "1                      8238.70                            2570.30   \n",
       "2                      1314.31                            2570.30   \n",
       "3                      8238.70                            2570.30   \n",
       "4                      1314.31                            2570.30   \n",
       "...                        ...                                ...   \n",
       "1046                   1314.31                            2570.30   \n",
       "1047                   8238.70                            2570.30   \n",
       "1048                   1314.31                            2570.30   \n",
       "1049                   1314.31                            2570.30   \n",
       "1050                   1314.31                            2570.30   \n",
       "\n",
       "      Home_Accessories_counts_enc  Footwear_counts_enc  automotive_counts_enc  \\\n",
       "0                         2715.52              2595.25                2607.29   \n",
       "1                         2715.52              2595.25                2607.29   \n",
       "2                         2715.52              2595.25                2607.29   \n",
       "3                         2715.52              2595.25                2607.29   \n",
       "4                         2715.52              2595.25                2607.29   \n",
       "...                           ...                  ...                    ...   \n",
       "1046                      2715.52              2595.25                2607.29   \n",
       "1047                      2715.52              2595.25                2607.29   \n",
       "1048                      2715.52              2595.25                1153.56   \n",
       "1049                       426.34              2595.25                2607.29   \n",
       "1050                      2715.52              2595.25                1153.56   \n",
       "\n",
       "      sports_counts_enc  others_counts_enc  \n",
       "0               2498.15            2521.49  \n",
       "1               2498.15            2521.49  \n",
       "2               2498.15            2521.49  \n",
       "3               2498.15            2521.49  \n",
       "4               2498.15            2521.49  \n",
       "...                 ...                ...  \n",
       "1046            2142.12            2521.49  \n",
       "1047            2498.15            2521.49  \n",
       "1048            2498.15            2521.49  \n",
       "1049            2498.15            2521.49  \n",
       "1050            2498.15            2521.49  \n",
       "\n",
       "[1051 rows x 40 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=pd.read_csv(path1)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['Unnamed: 0','Unnamed: 0.1'],1,inplace=True)\n",
    "test.drop(['Unnamed: 0','Unnamed: 0.1'],1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest regressor Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d4abbba8e894c4cb340149ed4416cd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=15, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=3,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=300, n_jobs=None, oob_score=False,\n",
       "                      random_state=9, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">  0.6921488952457707\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=15, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=3,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=300, n_jobs=None, oob_score=False,\n",
       "                      random_state=9, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">  0.6829643505089684\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=15, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=3,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=300, n_jobs=None, oob_score=False,\n",
       "                      random_state=9, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">  0.7192354150085499\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=15, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=3,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=300, n_jobs=None, oob_score=False,\n",
       "                      random_state=9, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">  0.7308711888170759\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=15, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=3,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=300, n_jobs=None, oob_score=False,\n",
       "                      random_state=9, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">  0.7093890046995288\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=15, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=3,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=300, n_jobs=None, oob_score=False,\n",
       "                      random_state=9, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">  0.6403940154849869\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=15, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=3,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=300, n_jobs=None, oob_score=False,\n",
       "                      random_state=9, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">  0.6426485108196468\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=15, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=3,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=300, n_jobs=None, oob_score=False,\n",
       "                      random_state=9, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">  0.6159435863540605\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=15, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=3,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=300, n_jobs=None, oob_score=False,\n",
       "                      random_state=9, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">  0.672824983364312\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=15, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=3,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=300, n_jobs=None, oob_score=False,\n",
       "                      random_state=9, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">  0.5557217972042569\n",
      "\n",
      "Mean: 0.666, Standard Deviation: 0.051\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "from sklearn import ensemble\n",
    "\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "FOLD=10\n",
    "X=train.drop('Selling_Price',1)\n",
    "y=(train['Selling_Price'])\n",
    "\n",
    "Xt=test.copy()\n",
    "test_preds = np.zeros(len(Xt))\n",
    "\n",
    "# k-fold cross validation\n",
    "scores=list()\n",
    "kf = KFold(n_splits=FOLD, shuffle=True,random_state=SEED)\n",
    "\n",
    "# enumerate splits\n",
    "\n",
    "for train_idx, test_idx in tqdm(kf.split(X, y)):\n",
    "    # get data\n",
    "    X_train, y_train = X.iloc[train_idx, :], y[train_idx]\n",
    "    X_test, y_test = X.iloc[test_idx, :], y[test_idx]\n",
    "    test=Xt\n",
    "    # fit model\n",
    "    model =RandomForestRegressor(random_state=9,bootstrap=True,max_depth=15,max_features='auto',min_samples_leaf=3,\n",
    "                                min_samples_split=2,n_estimators=300)\n",
    "    model.fit(X_train,np.log(y_train))\n",
    "    # evaluate model\n",
    "    yhat = np.exp((model.predict(X_test)))\n",
    "    test_preds += np.exp((model.predict(test)))/FOLD\n",
    "    acc = np.sqrt(mean_squared_log_error(y_test, yhat))\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    # store score\n",
    "    scores.append(acc)\n",
    "    print('> ', acc)\n",
    "    \n",
    "# summarize model performance\n",
    "# summarize model performance\n",
    "mean_s, std_s = np.mean(scores), np.std(scores)\n",
    "print('Mean: %.3f, Standard Deviation: %.3f' % (mean_s, std_s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGBM Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Fold 0 -----\n",
      "\n",
      "38 38\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 0.654253\tvalid_0's l2: 0.428047\n",
      "[200]\tvalid_0's rmse: 0.645677\tvalid_0's l2: 0.416899\n",
      "Early stopping, best iteration is:\n",
      "[137]\tvalid_0's rmse: 0.640516\tvalid_0's l2: 0.410261\n",
      "\n",
      " Fold 0.6405164636470948\n",
      "\n",
      "->-> Fold ran for 0 minutes 2 seconds\n",
      "\n",
      "---- Fold 1 -----\n",
      "\n",
      "38 38\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 0.698054\tvalid_0's l2: 0.48728\n",
      "[200]\tvalid_0's rmse: 0.667025\tvalid_0's l2: 0.444922\n",
      "[300]\tvalid_0's rmse: 0.667639\tvalid_0's l2: 0.445742\n",
      "Early stopping, best iteration is:\n",
      "[245]\tvalid_0's rmse: 0.665315\tvalid_0's l2: 0.442644\n",
      "\n",
      " Fold 0.6653148848718339\n",
      "\n",
      "->-> Fold ran for 0 minutes 2 seconds\n",
      "\n",
      "---- Fold 2 -----\n",
      "\n",
      "38 38\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 0.843537\tvalid_0's l2: 0.711554\n",
      "[200]\tvalid_0's rmse: 0.821496\tvalid_0's l2: 0.674856\n",
      "Early stopping, best iteration is:\n",
      "[199]\tvalid_0's rmse: 0.820942\tvalid_0's l2: 0.673946\n",
      "\n",
      " Fold 0.8209419052289146\n",
      "\n",
      "->-> Fold ran for 0 minutes 1 seconds\n",
      "\n",
      "---- Fold 3 -----\n",
      "\n",
      "38 38\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 0.708842\tvalid_0's l2: 0.502457\n",
      "[200]\tvalid_0's rmse: 0.724143\tvalid_0's l2: 0.524383\n",
      "Early stopping, best iteration is:\n",
      "[122]\tvalid_0's rmse: 0.706701\tvalid_0's l2: 0.499427\n",
      "\n",
      " Fold 0.706701340068216\n",
      "\n",
      "->-> Fold ran for 0 minutes 1 seconds\n",
      "\n",
      "---- Fold 4 -----\n",
      "\n",
      "38 38\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 0.649889\tvalid_0's l2: 0.422356\n",
      "[200]\tvalid_0's rmse: 0.625925\tvalid_0's l2: 0.391782\n",
      "Early stopping, best iteration is:\n",
      "[171]\tvalid_0's rmse: 0.622563\tvalid_0's l2: 0.387585\n",
      "\n",
      " Fold 0.6225629593693159\n",
      "\n",
      "->-> Fold ran for 0 minutes 1 seconds\n",
      "\n",
      "---- Fold 5 -----\n",
      "\n",
      "38 38\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 0.616841\tvalid_0's l2: 0.380493\n",
      "[200]\tvalid_0's rmse: 0.590699\tvalid_0's l2: 0.348926\n",
      "[300]\tvalid_0's rmse: 0.593878\tvalid_0's l2: 0.352691\n",
      "Early stopping, best iteration is:\n",
      "[207]\tvalid_0's rmse: 0.590211\tvalid_0's l2: 0.348349\n",
      "\n",
      " Fold 0.5902108667727559\n",
      "\n",
      "->-> Fold ran for 0 minutes 1 seconds\n",
      "\n",
      "---- Fold 6 -----\n",
      "\n",
      "38 38\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 0.655994\tvalid_0's l2: 0.430328\n",
      "[200]\tvalid_0's rmse: 0.656223\tvalid_0's l2: 0.430628\n",
      "Early stopping, best iteration is:\n",
      "[133]\tvalid_0's rmse: 0.649516\tvalid_0's l2: 0.421871\n",
      "\n",
      " Fold 0.6495160578443386\n",
      "\n",
      "->-> Fold ran for 0 minutes 1 seconds\n",
      "\n",
      "---- Fold 7 -----\n",
      "\n",
      "38 38\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 0.649617\tvalid_0's l2: 0.422002\n",
      "[200]\tvalid_0's rmse: 0.614672\tvalid_0's l2: 0.377822\n",
      "[300]\tvalid_0's rmse: 0.613392\tvalid_0's l2: 0.376249\n",
      "Early stopping, best iteration is:\n",
      "[269]\tvalid_0's rmse: 0.612012\tvalid_0's l2: 0.374558\n",
      "\n",
      " Fold 0.6120116407043292\n",
      "\n",
      "->-> Fold ran for 0 minutes 2 seconds\n",
      "\n",
      "---- Fold 8 -----\n",
      "\n",
      "38 38\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 0.625589\tvalid_0's l2: 0.391362\n",
      "[200]\tvalid_0's rmse: 0.589758\tvalid_0's l2: 0.347814\n",
      "[300]\tvalid_0's rmse: 0.590528\tvalid_0's l2: 0.348723\n",
      "Early stopping, best iteration is:\n",
      "[235]\tvalid_0's rmse: 0.588483\tvalid_0's l2: 0.346312\n",
      "\n",
      " Fold 0.588483099700889\n",
      "\n",
      "->-> Fold ran for 0 minutes 2 seconds\n",
      "\n",
      "---- Fold 9 -----\n",
      "\n",
      "38 38\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 0.79626\tvalid_0's l2: 0.63403\n",
      "[200]\tvalid_0's rmse: 0.773278\tvalid_0's l2: 0.597959\n",
      "[300]\tvalid_0's rmse: 0.770851\tvalid_0's l2: 0.594211\n",
      "Early stopping, best iteration is:\n",
      "[269]\tvalid_0's rmse: 0.769384\tvalid_0's l2: 0.591952\n",
      "\n",
      " Fold 0.7693844317244282\n",
      "\n",
      "->-> Fold ran for 0 minutes 2 seconds\n",
      "\n",
      "---- Fold 10 -----\n",
      "\n",
      "38 38\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 0.684511\tvalid_0's l2: 0.468555\n",
      "[200]\tvalid_0's rmse: 0.677249\tvalid_0's l2: 0.458666\n",
      "Early stopping, best iteration is:\n",
      "[157]\tvalid_0's rmse: 0.675173\tvalid_0's l2: 0.455859\n",
      "\n",
      " Fold 0.6751729541815692\n",
      "\n",
      "->-> Fold ran for 0 minutes 1 seconds\n",
      "\n",
      "---- Fold 11 -----\n",
      "\n",
      "38 38\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 0.646637\tvalid_0's l2: 0.41814\n",
      "[200]\tvalid_0's rmse: 0.596056\tvalid_0's l2: 0.355283\n",
      "[300]\tvalid_0's rmse: 0.585361\tvalid_0's l2: 0.342648\n",
      "[400]\tvalid_0's rmse: 0.579435\tvalid_0's l2: 0.335745\n",
      "[500]\tvalid_0's rmse: 0.577376\tvalid_0's l2: 0.333363\n",
      "Early stopping, best iteration is:\n",
      "[499]\tvalid_0's rmse: 0.577295\tvalid_0's l2: 0.333269\n",
      "\n",
      " Fold 0.5772948490084641\n",
      "\n",
      "->-> Fold ran for 0 minutes 3 seconds\n",
      "\n",
      "---- Fold 12 -----\n",
      "\n",
      "38 38\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 0.665541\tvalid_0's l2: 0.442944\n",
      "[200]\tvalid_0's rmse: 0.671235\tvalid_0's l2: 0.450557\n",
      "Early stopping, best iteration is:\n",
      "[121]\tvalid_0's rmse: 0.661182\tvalid_0's l2: 0.437162\n",
      "\n",
      " Fold 0.6611823318750703\n",
      "\n",
      "->-> Fold ran for 0 minutes 1 seconds\n",
      "\n",
      "---- Fold 13 -----\n",
      "\n",
      "38 38\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 0.698033\tvalid_0's l2: 0.48725\n",
      "[200]\tvalid_0's rmse: 0.682027\tvalid_0's l2: 0.465161\n",
      "Early stopping, best iteration is:\n",
      "[173]\tvalid_0's rmse: 0.679911\tvalid_0's l2: 0.462279\n",
      "\n",
      " Fold 0.6799112060795418\n",
      "\n",
      "->-> Fold ran for 0 minutes 2 seconds\n",
      "\n",
      "---- Fold 14 -----\n",
      "\n",
      "38 38\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 0.695549\tvalid_0's l2: 0.483789\n",
      "[200]\tvalid_0's rmse: 0.679385\tvalid_0's l2: 0.461564\n",
      "[300]\tvalid_0's rmse: 0.674674\tvalid_0's l2: 0.455185\n",
      "[400]\tvalid_0's rmse: 0.674508\tvalid_0's l2: 0.454961\n",
      "[500]\tvalid_0's rmse: 0.673828\tvalid_0's l2: 0.454044\n",
      "Early stopping, best iteration is:\n",
      "[478]\tvalid_0's rmse: 0.672811\tvalid_0's l2: 0.452675\n",
      "\n",
      " Fold 0.6728112841163847\n",
      "\n",
      "->-> Fold ran for 0 minutes 5 seconds\n",
      "\n",
      "---- Fold 15 -----\n",
      "\n",
      "38 38\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 0.708368\tvalid_0's l2: 0.501785\n",
      "[200]\tvalid_0's rmse: 0.657767\tvalid_0's l2: 0.432657\n",
      "[300]\tvalid_0's rmse: 0.654072\tvalid_0's l2: 0.42781\n",
      "[400]\tvalid_0's rmse: 0.652587\tvalid_0's l2: 0.42587\n",
      "[500]\tvalid_0's rmse: 0.651112\tvalid_0's l2: 0.423946\n",
      "Early stopping, best iteration is:\n",
      "[498]\tvalid_0's rmse: 0.650986\tvalid_0's l2: 0.423783\n",
      "\n",
      " Fold 0.65098613510314\n",
      "\n",
      "->-> Fold ran for 0 minutes 4 seconds\n",
      "\n",
      "---- Fold 16 -----\n",
      "\n",
      "38 38\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 0.684938\tvalid_0's l2: 0.46914\n",
      "[200]\tvalid_0's rmse: 0.676897\tvalid_0's l2: 0.458189\n",
      "Early stopping, best iteration is:\n",
      "[134]\tvalid_0's rmse: 0.674411\tvalid_0's l2: 0.45483\n",
      "\n",
      " Fold 0.6744106565941599\n",
      "\n",
      "->-> Fold ran for 0 minutes 1 seconds\n",
      "\n",
      "---- Fold 17 -----\n",
      "\n",
      "38 38\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 0.763354\tvalid_0's l2: 0.582709\n",
      "[200]\tvalid_0's rmse: 0.755529\tvalid_0's l2: 0.570824\n",
      "Early stopping, best iteration is:\n",
      "[148]\tvalid_0's rmse: 0.751872\tvalid_0's l2: 0.565312\n",
      "\n",
      " Fold 0.7518724196277444\n",
      "\n",
      "->-> Fold ran for 0 minutes 1 seconds\n",
      "\n",
      "---- Fold 18 -----\n",
      "\n",
      "38 38\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 0.738709\tvalid_0's l2: 0.545691\n",
      "[200]\tvalid_0's rmse: 0.729187\tvalid_0's l2: 0.531714\n",
      "Early stopping, best iteration is:\n",
      "[151]\tvalid_0's rmse: 0.725749\tvalid_0's l2: 0.526711\n",
      "\n",
      " Fold 0.7257488864300721\n",
      "\n",
      "->-> Fold ran for 0 minutes 1 seconds\n",
      "\n",
      "---- Fold 19 -----\n",
      "\n",
      "38 38\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 0.658026\tvalid_0's l2: 0.432998\n",
      "[200]\tvalid_0's rmse: 0.608511\tvalid_0's l2: 0.370285\n",
      "[300]\tvalid_0's rmse: 0.607607\tvalid_0's l2: 0.369186\n",
      "Early stopping, best iteration is:\n",
      "[266]\tvalid_0's rmse: 0.605702\tvalid_0's l2: 0.366875\n",
      "\n",
      " Fold 0.605702462345123\n",
      "\n",
      "->-> Fold ran for 0 minutes 2 seconds\n",
      "\n",
      "OOF val score: 0.6698824797378473\n",
      "\n",
      "->-> Total training time: 0 minutes 46 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "X=train.drop('Selling_Price',1)\n",
    "y=(train['Selling_Price'])\n",
    "\n",
    "Xt=test.copy()\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return mean_squared_error(y_true, y_pred) ** 0.5\n",
    "\n",
    "features = [c for c in X.columns]\n",
    "\n",
    "\n",
    "training_start_time = time.time()\n",
    "\n",
    "max_iter = 20\n",
    "folds = StratifiedKFold(n_splits = max_iter)\n",
    "oofs = np.zeros(len(X))\n",
    "test_preds = np.zeros(len(Xt))\n",
    "\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X, pd.qcut(y, 10, labels=False, duplicates='drop'))):\n",
    "    \n",
    "    print(f'\\n---- Fold {fold_} -----\\n')\n",
    "    \n",
    "    fold_start_time = time.time()\n",
    "    \n",
    "    X_trn, y_trn = X.iloc[trn_idx][features], y.iloc[trn_idx]\n",
    "    X_val, y_val = X.iloc[val_idx][features], y.iloc[val_idx]\n",
    "    X_test = Xt[features]\n",
    "    print(X_trn.shape[1], X_val.shape[1])\n",
    "    \n",
    "    \n",
    "    clf = LGBMRegressor(n_estimators=1000, num_leaves=127, max_depth=-1,min_child_samples=4, learning_rate=0.02, colsample_bytree=0.4, reg_alpha=0.5, reg_lambda=2)\n",
    "    _ = clf.fit(X_trn, np.log(y_trn), eval_set = [(X_val, np.log(y_val))], verbose=100, early_stopping_rounds=100, eval_metric='rmse')\n",
    "\n",
    "    oofs[val_idx] = np.exp(clf.predict(X_val))\n",
    "    current_test_pred = np.exp(clf.predict(X_test))\n",
    "    test_preds += np.exp(clf.predict(X_test))/max_iter\n",
    "    \n",
    "    \n",
    "    print(f'\\n Fold {rmse(np.log(y_val), np.log(oofs[val_idx]))}')\n",
    "    \n",
    "    fold_end_time = time.time()\n",
    "    total_fold_time = int(fold_end_time - fold_start_time)\n",
    "    \n",
    "    print(f\"\\n->-> Fold ran for {(total_fold_time)//60} minutes {(total_fold_time)%60} seconds\")\n",
    "    \n",
    "\n",
    "print(f'\\nOOF val score: {rmse(np.log(y), np.log(oofs))}')\n",
    "training_end_time = time.time()\n",
    "total_training_time = int(training_end_time - training_start_time)\n",
    "\n",
    "print(f'\\n->-> Total training time: {(total_training_time)//60} minutes {(total_training_time)%60} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking (RF+LGBM with Linear Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingRegressor(cv=10,\n",
       "                  estimators=[('knn',\n",
       "                               RandomForestRegressor(bootstrap=True,\n",
       "                                                     ccp_alpha=0.0,\n",
       "                                                     criterion='mse',\n",
       "                                                     max_depth=15,\n",
       "                                                     max_features='auto',\n",
       "                                                     max_leaf_nodes=None,\n",
       "                                                     max_samples=None,\n",
       "                                                     min_impurity_decrease=0.0,\n",
       "                                                     min_impurity_split=None,\n",
       "                                                     min_samples_leaf=3,\n",
       "                                                     min_samples_split=2,\n",
       "                                                     min_weight_fraction_leaf=0.0,\n",
       "                                                     n_estimators=300,\n",
       "                                                     n_jobs=None,\n",
       "                                                     oob_score=False,\n",
       "                                                     random_...\n",
       "                                             min_child_samples=4,\n",
       "                                             min_child_weight=0.001,\n",
       "                                             min_split_gain=0.0,\n",
       "                                             n_estimators=1000, n_jobs=-1,\n",
       "                                             num_leaves=127, objective=None,\n",
       "                                             random_state=None, reg_alpha=0.5,\n",
       "                                             reg_lambda=2, silent=True,\n",
       "                                             subsample=1.0,\n",
       "                                             subsample_for_bin=200000,\n",
       "                                             subsample_freq=0))],\n",
       "                  final_estimator=LinearRegression(copy_X=True,\n",
       "                                                   fit_intercept=True,\n",
       "                                                   n_jobs=None,\n",
       "                                                   normalize=False),\n",
       "                  n_jobs=None, passthrough=False, verbose=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6391289287313384\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "\n",
    "# define the base models\n",
    "level0 = list()\n",
    "level0.append(('knn', RandomForestRegressor(random_state=9,bootstrap=True,max_depth=15,max_features='auto',min_samples_leaf=3,\n",
    "                                min_samples_split=2,n_estimators=300)))\n",
    "level0.append(('lgb',LGBMRegressor(n_estimators=1000, num_leaves=127, max_depth=-1,min_child_samples=4, learning_rate=0.02, colsample_bytree=0.4,\n",
    "                                   reg_alpha=0.5, reg_lambda=2)))\n",
    "\n",
    "# define meta learner model\n",
    "level1 =LinearRegression()\n",
    "X=train.drop('Selling_Price',1)\n",
    "y=(train['Selling_Price'])\n",
    "\n",
    "# define the stacking ensemble\n",
    "model = StackingRegressor(estimators=level0, final_estimator=level1, cv=10)\n",
    "\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.3,random_state=9)\n",
    "\n",
    "# fit the model on all available data\n",
    "model.fit(X_train,np.log(y_train))\n",
    "\n",
    "y_pred=np.exp(model.predict(X_test))\n",
    "\n",
    "rmsle=np.sqrt(mean_squared_log_error(y_test,y_pred))\n",
    "print(rmsle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
